import os
import re
import time
from dotenv import load_dotenv
from supabase import create_client
from bs4 import BeautifulSoup

# =============================
# 0) Load ENV
# =============================
load_dotenv()

SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_KEY") or os.getenv("SUPABASE_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    raise EnvironmentError("âŒ í™˜ê²½ë³€ìˆ˜ SUPABASE_URL ë˜ëŠ” SUPABASE_SERVICE_KEY ëˆ„ë½")

supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# =============================
# 1) Clean Helper Functions
# =============================

def strip_html(text):
    """ë³¸ë¬¸ HTML íƒœê·¸ ì œê±°"""
    if not text:
        return ""
    try:
        return BeautifulSoup(text, "html.parser").get_text(separator=" ").strip()
    except:
        return text

def normalize(text):
    """ì—¬ë¶„ì˜ ê³µë°±, ê°œí–‰ ì œê±°"""
    if not text:
        return ""
    text = text.replace("\n", " ").replace("\t", " ")
    text = re.sub(r"\s+", " ", text)
    return text.strip()

def clean_event(row):
    """ì´ë²¤íŠ¸ 1ê°œ ì •ì œ"""
    title = normalize(row.get("title", ""))

    # raw í…ìŠ¤íŠ¸ â†’ HTML ì œê±° â†’ Normalize
    raw_text = row.get("raw_text") or row.get("summary") or ""
    clean_text = normalize(strip_html(raw_text))

    return {
        "raw_id": row["id"],
        "title": title,
        "clean_text": clean_text,
        "published_at": row.get("published_at"),
        "country": row.get("country"),
        "source": row.get("publisher") or row.get("platform"),
        "summary": None,
        "category": None,
        "tickers": None,
        "keywords": None,
        "sentiment": None,
    }

# =============================
# 2) Load RAW (KR Only + Dedup)
# =============================

def load_raw_kr(limit=100):
    """
    í•œêµ­(KR) ë°ì´í„°ë§Œ + title ì¤‘ë³µ ì œê±°
    """
    print(f"ðŸ“¥ RAW ì´ë²¤íŠ¸(KR only) ê°€ì ¸ì˜¤ê¸° (limit={limit})...")

    res = (
        supabase.schema("mm").table("events") \
        .select("*") \
        .eq("country", "KR") \
        .limit(limit * 3) \
        .execute()
    )

    rows = res.data
    print(f"ðŸ“Œ ê°€ì ¸ì˜¨ ê°œìˆ˜(ì¤‘ë³µ í¬í•¨): {len(rows)}")

    # ======== ðŸ”¥ ì œëª© ê¸°ì¤€ ì¤‘ë³µ ì œê±° ========
    seen = set()
    unique = []
    for r in rows:
        title = r.get("title", "").strip()
        if title and title not in seen:
            seen.add(title)
            unique.append(r)
        if len(unique) >= limit:
            break

    print(f"âœ¨ ì¤‘ë³µ ì œê±° í›„ ì‚¬ìš©: {len(unique)}ê°œ")
    return unique

# =============================
# 3) Save cleaned data
# =============================

def save_clean(rows_cleaned):
    print(f"ðŸ§¹ ì •ì œ ì™„ë£Œ: {len(rows_cleaned)}ê°œ â†’ ì €ìž¥ ì‹œìž‘")
    for c in rows_cleaned:
        try:
            supabase.schema("mm").table("events_cleaned").insert(c).execute()
        except Exception as e:
            print("âš  ì €ìž¥ ì˜¤ë¥˜:", e)


# =============================
# 4) Main
# =============================

def run(limit=100):
    rows = load_raw_kr(limit)
    cleaned = [clean_event(r) for r in rows]
    save_clean(cleaned)
    print("\nðŸŽ‰ TEST CLEAN 100ê±´ ì™„ë£Œ!")


if __name__ == "__main__":
    run(100)