import os
from supabase import create_client, ClientOptions
from datetime import datetime
import os
from dotenv import load_dotenv

load_dotenv()  # â† ì´ í•œ ì¤„ì´ í™˜ê²½ë³€ìˆ˜ë¥¼ ë¡œë“œí•œë‹¤

# ===============================
# 1) í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
# ===============================
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_KEY") or os.getenv("SUPABASE_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    raise EnvironmentError("âŒ í™˜ê²½ë³€ìˆ˜ SUPABASE_URL ë˜ëŠ” SUPABASE_KEY(SERVICE_KEY) ëˆ„ë½")

supabase = create_client(SUPABASE_URL, SUPABASE_KEY, options=ClientOptions(schema="mm"))

# ===============================
# 2) ë¬¸ì§€ê¸°(7B) â†’ ì •ì œ ê¸°ì¤€ (ê°„ë‹¨ ë²„ì „)
# ===============================
import re
from bs4 import BeautifulSoup

# ... (imports remain the same, but we need to add re and bs4)

# ===============================
# 2) ë¬¸ì§€ê¸°(7B) â†’ ì •ì œ ê¸°ì¤€ (ê°„ë‹¨ ë²„ì „)
# ===============================
def clean_text(text: str):
    """ìš”ì•½ê³¼ HTML ì œê±° ë“± ê¸°ë³¸ ì •ì œ"""
    if not text:
        return None

    # 1. HTML ì œê±° (BeautifulSoup)
    try:
        soup = BeautifulSoup(text, "html.parser")
        text = soup.get_text(separator=" ")
    except Exception:
        pass  # BS4 ì‹¤íŒ¨ ì‹œ ì›ë³¸ ìœ ì§€ í˜¹ì€ ì¶”ê°€ ì²˜ë¦¬

    # 2. ê³µë°± ì •ê·œí™” (ì—°ì†ëœ ê³µë°± -> ê³µë°± 1ê°œ)
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text


def clean_event(row: dict):
    """ë‹¨ì¼ ì´ë²¤íŠ¸ ì •ì œ"""
    return {
        "raw_id": row.get("id"),
        "title": row.get("title"),
        "clean_text": clean_text(row.get("raw_text") or row.get("summary")),
        "summary": clean_text(row.get("summary")),
        "category": row.get("category"),
        "tickers": [row.get("ticker")] if row.get("ticker") else [],
        "keywords": row.get("keywords"),
        "sentiment": row.get("sentiment"),
        "published_at": row.get("published_at"),
        "source": row.get("publisher"),
        "country": row.get("country"),
    }


# ===============================
# 3) Supabaseì—ì„œ RAW ì½ì–´ì˜¤ê¸°
# ===============================
def fetch_raw_events(start: int, end: int):
    # range is inclusive of start, exclusive of end in Python slicing, 
    # but Supabase range is inclusive-inclusive usually. 
    # Let's check supabase-py docs or assume standard 0-indexed offset.
    # .range(0, 9) returns 10 items.
    res = supabase.table("events").select("*").range(start, end).execute()
    return res.data or []


# ===============================
# 4) ì •ì œ í›„ Supabaseì— ì €ì¥
# ===============================
def save_cleaned(clean_rows: list):
    if not clean_rows:
        return

    res = supabase.table("events_cleaned").insert(clean_rows).execute()
    # print(f"âœ” Supabase ì €ì¥ ì™„ë£Œ: {len(clean_rows)} rows")


# ===============================
# 5) ì „ì²´ ì‹¤í–‰
# ===============================
def run(total_limit=100000, batch_size=1000):
    print(f"\nï¿½ ì´ {total_limit}ê°œ ì´ë²¤íŠ¸ ì •ì œ ì‹œì‘ (Batch Size: {batch_size})...")
    
    processed_count = 0
    
    for start in range(0, total_limit, batch_size):
        end = start + batch_size - 1
        
        # 1. Fetch
        raw_events = fetch_raw_events(start, end)
        if not raw_events:
            print(f"ğŸ ë” ì´ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (Processed: {processed_count})")
            break
            
        # 2. Clean
        cleaned = []
        for r in raw_events:
            c = clean_event(r)
            if c:
                cleaned.append(c)
        
        # 3. Save
        if cleaned:
            save_cleaned(cleaned)
            processed_count += len(cleaned)
            print(f"âœ” Batch {start}~{end}: {len(cleaned)}ê°œ ì €ì¥ ì™„ë£Œ (ëˆ„ì : {processed_count})")
        else:
            print(f"âš  Batch {start}~{end}: ì €ì¥í•  ë°ì´í„° ì—†ìŒ")

    print(f"\nâœ¨ ì „ì²´ ì™„ë£Œ! ì´ {processed_count}ê°œ ì •ì œë¨.")


if __name__ == "__main__":
    # 10ë§Œê°œ ì²˜ë¦¬
    run(total_limit=500000, batch_size=1000)