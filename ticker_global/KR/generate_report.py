import pandas as pd
from collections import Counter
import os
import datetime

def analyze_and_generate_report(input_path, output_path):
    print(f"Loading data from {input_path}...")
    df = pd.read_csv(input_path)
    
    # Convert published_at to datetime
    df['published_at'] = pd.to_datetime(df['published_at'], errors='coerce')
    
    # Filter for the latest available date in the dataset to simulate "Today's Briefing"
    latest_date = df['published_at'].max().date()
    target_date_str = latest_date.strftime('%Y-%m-%d')
    print(f"Generating report for date: {target_date_str}")
    
    # Filter data for that date
    daily_df = df[df['published_at'].dt.date == latest_date]
    
    if daily_df.empty:
        print("No data found for the latest date.")
        return

    # --- Analytics ---
    
    # 1. Top Signals (High Volume Tickers/Concepts)
    ticker_counts = daily_df['ticker'].value_counts().head(5)
    top_tickers = ticker_counts.index.tolist()
    
    # 2. Sentiment Analysis by Sector/Macro
    # Assuming 'sentiment' column exists and is numeric or convertible. 
    # If it's text (positive/negative), we map it.
    # For this script, let's assume it's missing or raw text, so we'll use keyword frequency as a proxy for "Heat".
    
    # 3. Extract Headlines for Top Tickers
    top_headlines = {}
    for ticker in top_tickers:
        row = daily_df[daily_df['ticker'] == ticker].iloc[0]
        top_headlines[ticker] = {
            "name": row['company_name'],
            "title": row['title'],
            "type": row.get('ticker_type', 'COMPANY')
        }

    # 4. Sector Trends
    sectors = daily_df[daily_df['ticker_type'] == 'SECTOR']['company_name'].value_counts().head(3).index.tolist()
    sector_summary = []
    for sector in sectors:
        headlines = daily_df[daily_df['company_name'] == sector]['title'].head(2).tolist()
        sector_summary.append(f"- **{sector}**: {headlines[0] if headlines else 'ê´€ë ¨ ë‰´ìŠ¤ ì—†ìŒ'}")

    # 5. Macro/Risk Analysis
    macro_df = daily_df[daily_df['ticker_type'].isin(['MACRO', 'COMMODITY'])]
    macro_headlines = macro_df['title'].head(3).tolist()

    # --- Report Generation (Template Filling) ---
    
    report_content = f"""
==============================
ğŸ“Œ **ì˜¤ëŠ˜ì˜ êµ­ë‚´ ê²½ì œ ë¸Œë¦¬í•‘** ({target_date_str})
(ì†Œë¹„ì ëŒ€ìƒ / ë°ì´í„° ê¸°ë°˜ ë¶„ì„)

### 1) ì˜¤ëŠ˜ ê°€ì¥ ê°•í•œ ì‹œê·¸ë„ (Top 3)
"""
    for i, ticker in enumerate(top_tickers[:3]):
        info = top_headlines[ticker]
        report_content += f"- **[{info['name']}]**: {info['title']}\n"

    report_content += f"""
### 2) ìƒí™œ ê²½ì œì— ì§ì ‘ ì˜í–¥ (Macro & Consumer)
- **ê±°ì‹œê²½ì œ íë¦„**: {macro_headlines[0] if macro_headlines else 'íŠ¹ì´ì‚¬í•­ ì—†ìŒ'}
- **ì†Œë¹„ì ì˜í–¥**: ìµœê·¼ {top_headlines[top_tickers[0]]['name']} ê´€ë ¨ ì´ìŠˆê°€ ì‹œì¥ì˜ ì£¼ëª©ì„ ë°›ê³  ìˆìœ¼ë©°, ì´ëŠ” íˆ¬ì ì‹¬ë¦¬ì— ì§ì ‘ì ì¸ ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### 3) ì‚°ì—…ë³„ ì£¼ìš” íë¦„ (Sector Trends)
"""
    for item in sector_summary:
        report_content += f"{item}\n"

    report_content += """
### 4) ì˜¤ëŠ˜ì˜ ë¦¬ìŠ¤í¬ & ê¸°íšŒ
- **[Risk]**: ê¸€ë¡œë²Œ ë¶ˆí™•ì‹¤ì„±(í™˜ìœ¨/ê¸ˆë¦¬)ì´ ì—¬ì „íˆ ìƒì¡´í•˜ëŠ” ê°€ìš´ë°, ë§¤í¬ë¡œ ì§€í‘œì˜ ë³€ë™ì„±ì— ìœ ì˜í•´ì•¼ í•©ë‹ˆë‹¤.
- **[Opportunity]**: ê±°ë˜ëŸ‰ì´ ê¸‰ì¦í•œ ì„¹í„°ë‚˜ ê¸°ì—…(ìœ„ ì‹œê·¸ë„ ì°¸ì¡°)ì—ì„œ ë‹¨ê¸°ì ì¸ ëª¨ë©˜í…€ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### 5) í•œ ë¬¸ì¥ ìš”ì•½
"""
    main_topic = top_headlines[top_tickers[0]]['name']
    report_content += f'"ì˜¤ëŠ˜ í•œêµ­ ê²½ì œëŠ” **{main_topic}** ì´ìŠˆê°€ ì‹œì¥ì„ ì£¼ë„í•˜ë©° ëšœë ·í•œ ë°©í–¥ì„±ì„ ë³´ì˜€ìŠµë‹ˆë‹¤."'
    
    report_content += "\n=============================="

    print(f"Saving report to {output_path}...")
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(report_content)
    print("Done!")

if __name__ == "__main__":
    BASE_DIR = "/Users/js/g9"
    # The file is in "ticker_global/KR/csv/"
    INPUT_CSV = os.path.join(BASE_DIR, "ticker_global/KR/csv/cleaned_events_final.csv")
    OUTPUT_REPORT = os.path.join(BASE_DIR, "ticker_global/KR/daily_briefing.md")
    
    analyze_and_generate_report(INPUT_CSV, OUTPUT_REPORT)
